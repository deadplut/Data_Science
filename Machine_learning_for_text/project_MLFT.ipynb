{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #CCCCFF; border-radius: 1px;\">\n",
    "<div style=\"margin: 5px\">\n",
    "<b class=\"alert-heading\">Комментарий ревьюера</b>\n",
    "<p>Борис, привет!</p>\n",
    "<p>Меня зовут Алексей Секоцкий. Поздравляю с подготовкой очередного проекта. Предлагаю обращаться друг к другу на «ты» если нет возражений. Ниже стандартный блок с условными обозначениями:</p>\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "всё отлично\n",
    "</div>\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "рекомендации на будущее (не требующие доработки проекта)\n",
    "</div>\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "критичные моменты требующие внимания (доработки)\n",
    "</div>\n",
    "<div class=\"alert alert-info\">\n",
    "информационные комментарии и итоговый\n",
    "</div>\n",
    "\n",
    "<hr>\n",
    "<p>Пожалуйста, не изменяй и не удаляй мои комментарии – они потребуются для повторной проверки (при необходимости). Задавай вопросы и описывай сделанные изменения, помечая их любым удобным наглядным способом.</p>\n",
    "    \n",
    "   \n",
    "<div class=\"alert alert-info\">\n",
    "<b class=\"alert-heading\">Комментарий студента:</b>\n",
    "Добрый день, Алексей, Спасибо за проверку проекта! У меня есть одна просьба: одолжить один цвет для моих комментариев исправлений ошибок и тд, так как другие цвета у меня не получается подгрузить: \n",
    "</div>\n",
    "<div class=\"alert alert-primary\" role=\"alert\">\n",
    "  Это основное уведомление — check it out!\n",
    "</div>\n",
    "<div class=\"alert alert-secondary\" role=\"alert\">\n",
    "  Это дополнительное уведомление — check it out!\n",
    "</div>\n",
    "</div>\n",
    "<div class=\"alert alert-light\" role=\"alert\">\n",
    "  Это инфо-уведомление — check it out!\n",
    "</div>\n",
    "<div class=\"alert alert-dark\" role=\"alert\">\n",
    "  Это темное уведомление — check it out!\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-info\">\n",
    "<b class=\"alert-heading\">Комментарий студента:</b>\n",
    "У меня возник вопрос по комментарию: \"Использование кросс-валидации в обычном виде нежелательно, потому что в валидационную выборку попадают части частот слов и происходит утечка.\" \n",
    "Что нужно указать, чтобы избежать данной утечки?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Введение\" data-toc-modified-id=\"Введение-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Введение<a id=\"intro\"></a></a></span></li><li><span><a href=\"#Оглавление:\" data-toc-modified-id=\"Оглавление:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Оглавление:</a></span></li><li><span><a href=\"#1.-Подготовка\" data-toc-modified-id=\"1.-Подготовка-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>1. Подготовка<a id=\"preparing\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Открытие-и-изучиние-файлов\" data-toc-modified-id=\"1.1-Открытие-и-изучиние-файлов-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>1.1 Открытие и изучиние файлов<a id=\"open\"></a></a></span></li><li><span><a href=\"#1.2-Подготовка-данных-к-обучению\" data-toc-modified-id=\"1.2-Подготовка-данных-к-обучению-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>1.2 Подготовка данных к обучению<a id=\"preparation\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Разбиение-датасета-на-тестовые-и-тренировочные-выборки.\" data-toc-modified-id=\"Разбиение-датасета-на-тестовые-и-тренировочные-выборки.-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Разбиение датасета на тестовые и тренировочные выборки.</a></span></li><li><span><a href=\"#Вычисление-TF-IDF\" data-toc-modified-id=\"Вычисление-TF-IDF-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Вычисление TF-IDF</a></span></li></ul></li></ul></li><li><span><a href=\"#2.-Обучение-\" data-toc-modified-id=\"2.-Обучение--4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>2. Обучение <a id=\"training\"></a></a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Логистическая-регрессия-без-кросс-валидации\" data-toc-modified-id=\"2.1-Логистическая-регрессия-без-кросс-валидации-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>2.1 Логистическая регрессия без кросс-валидации<a id=\"3.1\"></a></a></span></li><li><span><a href=\"#2.2-Логистическая-регрессия-с-кросс-валидацией\" data-toc-modified-id=\"2.2-Логистическая-регрессия-с-кросс-валидацией-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>2.2 Логистическая регрессия с кросс-валидацией<a id=\"3.2\"></a></a></span></li><li><span><a href=\"#2.3-Случайный-лес\" data-toc-modified-id=\"2.3-Случайный-лес-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>2.3 Случайный лес<a id=\"3.3\"></a></a></span></li><li><span><a href=\"#2.4-Дерево-решений\" data-toc-modified-id=\"2.4-Дерево-решений-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>2.4 Дерево решений<a id=\"3.4\"></a></a></span></li></ul></li><li><span><a href=\"#Вывод-\" data-toc-modified-id=\"Вывод--5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Вывод <a id=\"conclusion\"></a></a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение<a id=\"intro\"></a>\n",
    "\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "План работы: \n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Вывод.\n",
    "\n",
    "Описание данных:\n",
    " - *text*  - текст комментария, \n",
    " - *toxic* - целевой признак.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка<a id=\"preparing\"></a>\n",
    "### 1.1 Открытие и изучиние файлов<a id=\"open\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библеотек\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from tqdm import notebook\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Открытие данных\n",
    "df = pd.read_csv('toxic_comments.csv')\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В загруженном датасете 159571 записей. Пропусков нет, дубликатов нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Подготовка данных к обучению<a id=\"preparation\"></a>\n",
    "#### Очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    return \" \".join(re.sub(r'[^a-zA-Z]',' ', text).split())\n",
    "df['lemma'] = df['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23324     Backstreet Boys Backstreet Boys article was bl...\n",
      "141663    Image Why can we use these images Image X japa...\n",
      "88428     Hey Jerk You need to read the editnotice well ...\n",
      "35802     YA GODDAMIT IDIOT MY IP CHANGES WHEN AN ADMIST...\n",
      "130301    Thank you for experimenting with Wikipedia You...\n",
      "Name: lemma, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['lemma'].sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение датасета на тестовые, тренировочные и валидационные выборки.<a id='valid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер тренировочной выборки: 95742\n",
      "Размер валидационной выборки: 31914\n",
      "Размер тестовой выборки: 31915\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.lemma, df.toxic, test_size=0.4, random_state=12345)\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(\n",
    "    x_test, y_test, test_size=0.5, random_state=12345)\n",
    "\n",
    "print('Размер тренировочной выборки:', x_train.count())\n",
    "print('Размер валидационной выборки:',x_valid.count())\n",
    "print('Размер тестовой выборки:',x_test.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вычисление TF-IDF\n",
    "Для тренировочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sugan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95742, 125610)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = x_train\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, lowercase=True)\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "У нас текст в основном английский. Переводить в Unicode (`.values.astype('U')`) не нужно. В тренажере мы работали с русским текстом, поэтому там это было оправдано. Путем экспериментов коллега вывел, что на полном датасете из-за предобразвания в Unicode отъедатся около 3 Гб памяти и ядро падает :) Нам такое не нужно :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "При использовании TF-IDF необходимо также добавить очистку или лемматизацию текста. Проще реализовать очистку (в теории по спринту – тема «Регулярные выражения») и привести все символы к нижнему регистру (.lower()  или в tf-idf lowercase=True). Если будет желание сделать лемматизацию, то необходимо обратить внимание на следующие особенности: лемматизатор должен поддерживать английский язык. Также должен либо уметь сразу работать с предложениями, либо, если ты выберешь лемматризатор, который работает по одному слову, то разбить предложения на слова, провести лемматизацию и снова собрать отдельные слова в предложения. <a href=\"https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\">Здесь</a> можно прочитать подробнее.\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b class=\"alert-heading\">Комментарий студента:</b>\n",
    "\n",
    "1. Убрал перевод в Unicode.\n",
    "\n",
    "2. Добавил очистку и привел к нижнему регистру в tf-idf lowercase=True\n",
    "    \n",
    "3. Пытался добавить лемматизацию текста через NLTK и spaCy, но библиотека NLTK отказывалось лемматизировать список, а через цикл каждое слово приводить к лемме мучительно долго выходит, а библиотека spaCy постоянно требовало что-либо подгрузить дополнительно, но к jupiter notebook у меня не получилось жто всё подключить.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31914, 125610)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = x_valid\n",
    "tf_idf_valid = count_tf_idf.transform(corpus)\n",
    "tf_idf_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31915, 125610)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = x_test\n",
    "tf_idf_test = count_tf_idf.transform(corpus)\n",
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Хорошо, что TF-IDF настраивается на обучающей выборке, а для теста используется transform без fit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Обучение <a id='training'></a>\n",
    "### 2.1 Логистическая регрессия<a id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для логистической регрессии без кросс-валидации: 0.7532967032967033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\praktikum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight='balanced').fit(tf_idf, y_train)\n",
    "predictions = model.predict(tf_idf_valid)\n",
    "f1 = f1_score(y_valid, predictions)\n",
    "print('f1 для логистической регрессии без кросс-валидации:', f1)\n",
    "\n",
    "# Список показателей f1 моделей\n",
    "f1_list = []\n",
    "f1_list.append(f1.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Использование кросс-валидации в обычном виде нежелательно, потому что в валидационную выборку попадают части частот слов и происходит утечка. Если будет принято решение отказаться от кросс-валидации, то необходимо поделить данные выше на 3 выборки: добавить валидационную.\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b class=\"alert-heading\">Комментарий студента:</b>\n",
    "\n",
    "1. Убрал кросс-валидацию\n",
    "\n",
    "2. Добавил [валидационную выборку](#valid)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Случайный лес<a id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d715359ef8a04d2187587e2a2608f167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Налилучший показатель F1 = 0.45306532663316584 для случайного леса достигается при глубине равной 130:\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "\n",
    "\n",
    "for depth in notebook.tqdm(range(50, 150, 10)):\n",
    "    model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=1).fit(tf_idf, y_train)\n",
    "    preditions = model.predict(tf_idf_valid)\n",
    "    f1 = f1_score(y_valid,preditions)\n",
    "    \n",
    "    if best_f1 < f1:\n",
    "        best_model = model\n",
    "        best_f1 = f1\n",
    "        best_depth = depth\n",
    "        \n",
    "            \n",
    "print('Налилучший показатель F1 = {} для случайного леса достигается при глубине равной {}:'.format(best_f1,best_depth) )\n",
    "\n",
    "# запись f1\n",
    "f1_list.append(best_f1.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Дерево решений<a id=\"3.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1a84d5c77e45619589abbb51187f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Налилучший показатель F1 = 0.7340479836651354 для дерева решений достигается при глубине равной 100:\n"
     ]
    }
   ],
   "source": [
    "best_depth = 0\n",
    "best_model = None\n",
    "best_f1 = 0\n",
    "\n",
    "for depth in notebook.tqdm(range(50, 150, 10)):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth).fit(tf_idf, y_train)\n",
    "    predictions = model.predict(tf_idf_valid)\n",
    "    f1 = f1_score(y_valid, predictions)\n",
    "    if best_f1 < f1:\n",
    "        best_f1 = f1\n",
    "        best_depth = depth\n",
    "        best_model = model\n",
    "\n",
    "print('Налилучший показатель F1 = {} для дерева решений достигается при глубине равной {}:'.format(best_f1,best_depth) )\n",
    "\n",
    "# запись f1\n",
    "f1_list.append(best_f1.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de04cde9e4d140fe8eff6e34a3aef076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Налилучший показатель F1 = 0.763264586638463 для дерева решений достигается при количестве деревьев равным 150:\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_f1 = 0\n",
    "best_est = 0\n",
    "for est in notebook.tqdm(range(100, 151, 25)):\n",
    "    model = LGBMClassifier(random_state=12345, n_estimators=est).fit(tf_idf, y_train)\n",
    "    preditions = model.predict(tf_idf_valid)\n",
    "    f1 = f1_score(y_valid, preditions)\n",
    "    if f1 > best_f1:\n",
    "        best_model = model\n",
    "        best_f1 = f1\n",
    "        best_est = est\n",
    "            \n",
    "        \n",
    "print('Налилучший показатель F1 = {} для дерева решений достигается при количестве деревьев равным {}:'.format(best_f1,best_est) )\n",
    "# запись f1\n",
    "f1_list.append(best_f1.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Логистическая регрессия без кросс-валидации</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Дерево решений</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               f1\n",
       "Логистическая регрессия без кросс-валидации  0.75\n",
       "Дерево решений                               0.45\n",
       "Случайный лес                                0.73\n",
       "LGBMClassifier                               0.76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_list = ['Логистическая регрессия без кросс-валидации', 'Дерево решений', \"Случайный лес\", 'LGBMClassifier' ]\n",
    "d = {'f1': f1_list}\n",
    "result = pd.DataFrame(data=d, index = index_list)\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестирования возьмем Логистическую регрессию и LGBMClassifier, так как показатели F1 больше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Неплохой результат в этом проекте может дать LGBMClassifier, но перевод в Unicode необходимо отключить иначе с большой вероятностью не хватить ресурсов и ядро «упадет».\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b class=\"alert-heading\">Комментарий студента:</b>\n",
    "\n",
    "1. Добавил LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Тестирование\n",
    "### 3.1 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для логистической регрессии: 0.7524587893059981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\anaconda3\\envs\\praktikum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight='balanced').fit(tf_idf, y_train)\n",
    "predictions = model.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print('f1 для логистической регрессии:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для LGBMClassifier: 0.7743170349747696\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(random_state=12345, n_estimators=500).fit(tf_idf, y_train)\n",
    "preditions = model.predict(tf_idf_test)\n",
    "f1 = f1_score(y_test, preditions)\n",
    "print('f1 для LGBMClassifier:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод <a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведена предобработка данных и обучена модель линейной регрессией, случайным лесом, деревом решиний.\n",
    "Наилучшие показатели метрики показала модель, обученная LGBMClassifier: F1 = 0.77.\n",
    "\n",
    "Исходя из  результатов теста предлагаю модель LGBMClassifier, так как удовлетворяет условию поставленной задаче.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Комментарий ревьюера</b>\n",
    "\n",
    "Отлично, требуемая метрика достигнута.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Итоговый комментарий ревьюера</b>\n",
    "\n",
    "Хорошее начало. Есть несколько важных моментов, требующих внимания: добавить очистку или лемматизацию и разобраться с кросс-валидацией. Буду ждать новую версию!\n",
    "<hr>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
